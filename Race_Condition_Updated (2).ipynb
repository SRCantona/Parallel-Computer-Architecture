{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8l4VcZkdmHw6",
        "outputId": "c5745c8f-a1e4-4b4f-e807-f71eb0ab0f53",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DataFrame BEFORE race condition:\n",
            "         Date   Price    Open     High      Low    Vol. Change %\n",
            "0  12/30/2022  1826.2  1821.8  1832.40  1819.80  107.50    0.01%\n",
            "1  12/29/2022  1826.0  1812.3  1827.30  1811.20  105.99    0.56%\n",
            "2  12/28/2022  1815.8  1822.4  1822.80  1804.20  118.08   -0.40%\n",
            "3  12/27/2022  1823.1  1808.2  1841.90  1808.00  159.62    0.74%\n",
            "4  12/26/2022  1809.7  1805.8  1811.95  1805.55     NaN    0.30%\n",
            "\n",
            "DataFrame AFTER race condition:\n",
            "         Date   Price    Open     High      Low    Vol. Change %\n",
            "0  12/30/2022  1826.2  1821.8  1832.40  1819.80  107.50    0.01%\n",
            "1  12/29/2022  1827.0  1812.3  1827.30  1811.20  105.99    0.56%\n",
            "2  12/28/2022  1815.8  1822.4  1822.80  1804.20  128.08   -0.40%\n",
            "3  12/27/2022  1823.1  1808.2  1841.90  1808.00  159.62    0.74%\n",
            "4  12/26/2022  1809.7  1805.8  1811.95  1805.55     NaN    0.30%\n",
            "\n",
            "Execution Time: 0.7353 seconds\n",
            "\n",
            "R2 Score: 0.999305193278458\n",
            "Mean Squared Error: 47.382999248870405\n"
          ]
        }
      ],
      "source": [
        "# Import libraries\n",
        "import pandas as pd\n",
        "import threading\n",
        "import random\n",
        "import time\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import r2_score, mean_squared_error\n",
        "\n",
        "# Load the dataset\n",
        "df = pd.read_csv(\"Gold Price (2013-2023).csv\")\n",
        "\n",
        "# Fix numeric columns with commas\n",
        "numeric_columns = [\"Price\", \"Open\", \"High\", \"Low\"]\n",
        "for col in numeric_columns:\n",
        "    df[col] = df[col].str.replace(\",\", \"\").astype(float)\n",
        "\n",
        "# Convert \"Vol.\" column to numeric, handling \"K\"\n",
        "df['Vol.'] = df['Vol.'].str.replace(\"K\", \"000\", regex=True)\n",
        "df['Vol.'] = df['Vol.'].astype(float)\n",
        "\n",
        "# Capture the initial state of the DataFrame\n",
        "before_update = df.copy()\n",
        "\n",
        "# Start the timer for execution time measurement\n",
        "start_time = time.time()\n",
        "\n",
        "# Simulating shared resource access and random modification\n",
        "random.seed(42)  # Set seed for reproducibility\n",
        "\n",
        "def increment_price_random():\n",
        "    global df\n",
        "    for _ in range(1000):\n",
        "        idx = random.randint(0, len(df) - 1)  # Random row index\n",
        "        df.at[idx, \"Price\"] += 1  # Increment the price of a random row\n",
        "\n",
        "def decrement_price_random():\n",
        "    global df\n",
        "    for _ in range(1000):\n",
        "        idx = random.randint(0, len(df) - 1)  # Random row index\n",
        "        df.at[idx, \"Price\"] -= 1  # Decrement the price of a random row\n",
        "\n",
        "def increment_volume_random():\n",
        "    global df\n",
        "    for _ in range(1000):\n",
        "        idx = random.randint(0, len(df) - 1)  # Random row index\n",
        "        df.at[idx, \"Vol.\"] += 10  # Increment the volume of a random row\n",
        "\n",
        "def decrement_volume_random():\n",
        "    global df\n",
        "    for _ in range(1000):\n",
        "        idx = random.randint(0, len(df) - 1)  # Random row index\n",
        "        df.at[idx, \"Vol.\"] -= 10  # Decrement the volume of a random row\n",
        "\n",
        "# Create threads\n",
        "thread1 = threading.Thread(target=increment_price_random)\n",
        "thread2 = threading.Thread(target=decrement_price_random)\n",
        "thread3 = threading.Thread(target=increment_volume_random)\n",
        "thread4 = threading.Thread(target=decrement_volume_random)\n",
        "\n",
        "# Start threads\n",
        "thread1.start()\n",
        "thread2.start()\n",
        "thread3.start()\n",
        "thread4.start()\n",
        "\n",
        "# Wait for threads to finish\n",
        "thread1.join()\n",
        "thread2.join()\n",
        "thread3.join()\n",
        "thread4.join()\n",
        "\n",
        "# End the timer\n",
        "end_time = time.time()\n",
        "\n",
        "# Capture the final state of the DataFrame\n",
        "after_update = df.copy()\n",
        "\n",
        "# Print the DataFrame before and after the race condition\n",
        "print(\"DataFrame BEFORE race condition:\")\n",
        "print(before_update.head())\n",
        "\n",
        "print(\"\\nDataFrame AFTER race condition:\")\n",
        "print(after_update.head())\n",
        "\n",
        "# Record execution time\n",
        "execution_time = end_time - start_time\n",
        "print(f\"\\nExecution Time: {execution_time:.4f} seconds\")\n",
        "\n",
        "# Preprocessing for machine learning\n",
        "X = df[[\"Open\", \"High\", \"Low\", \"Vol.\"]]\n",
        "y = df[\"Price\"]\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Standardize the data\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Train a Random Forest model\n",
        "rf_model = RandomForestRegressor(random_state=42, n_estimators=100)\n",
        "rf_model.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Make predictions and evaluate\n",
        "y_pred = rf_model.predict(X_test_scaled)\n",
        "print(\"\\nR2 Score:\", r2_score(y_test, y_pred))\n",
        "print(\"Mean Squared Error:\", mean_squared_error(y_test, y_pred))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f7f40b29"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Critical Section using threading.Lock\n",
        "lock = threading.Lock()\n",
        "\n",
        "def increment_price_random():\n",
        "    global df\n",
        "    for _ in range(1000):\n",
        "        idx = random.randint(0, len(df) - 1)\n",
        "        with lock:  # Critical section\n",
        "            df.at[idx, \"Price\"] += 1\n",
        "\n",
        "def decrement_price_random():\n",
        "    global df\n",
        "    for _ in range(1000):\n",
        "        idx = random.randint(0, len(df) - 1)\n",
        "        with lock:\n",
        "            df.at[idx, \"Price\"] -= 1\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2276844e"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Reduction Technique\n",
        "thread_changes = []\n",
        "\n",
        "def increment_price_random_reduction():\n",
        "    local_changes = []\n",
        "    for _ in range(1000):\n",
        "        idx = random.randint(0, len(df) - 1)\n",
        "        local_changes.append((idx, 1))\n",
        "    thread_changes.append(local_changes)\n",
        "\n",
        "def apply_reduction():\n",
        "    for changes in thread_changes:\n",
        "        for idx, change in changes:\n",
        "            df.at[idx, \"Price\"] += change\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8c3726bb",
        "outputId": "49cdc7e6-d8f4-42b5-a599-d5a73a9eaffb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cores: 1, Execution Time: 0.0822 seconds\n",
            "Cores: 2, Execution Time: 0.1460 seconds\n",
            "Cores: 4, Execution Time: 0.2917 seconds\n",
            "Cores: 8, Execution Time: 0.5613 seconds\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Analyzing Performance with Multiple Cores\n",
        "from multiprocessing import Pool\n",
        "\n",
        "def worker_function(core_id):\n",
        "    increment_price_random()\n",
        "\n",
        "cores = [1, 2, 4, 8]\n",
        "for core_count in cores:\n",
        "    start_time = time.time()\n",
        "    with Pool(core_count) as pool:\n",
        "        pool.map(worker_function, range(core_count))\n",
        "    end_time = time.time()\n",
        "    print(f\"Cores: {core_count}, Execution Time: {end_time - start_time:.4f} seconds\")\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.2"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}